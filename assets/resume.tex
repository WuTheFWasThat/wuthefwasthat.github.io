\documentclass[11 pt]{article}
\usepackage{hyperref}
%\usepackage{newcent}
\usepackage{amsmath}
\usepackage{amssymb}
%\usepackage{mathrsfs}
\usepackage{verbatim}


\pdfpagewidth 8.5in
\pdfpageheight 11in
\topmargin -1in
\headheight 0in
\headsep 0in
\textheight 8.5in
\textwidth 6.5in
\oddsidemargin 0in
\evensidemargin 0in
\headheight 75pt
\headsep 0in
\footskip 0.75in

\begin{document}

\begin{center}
% \begin{LARGE}\textsc{\textbf{Curriculum Vitae}}\end{LARGE} \\ \vspace{6 pt}
\begin{LARGE}\textsc{\textbf{Jeffrey Wu}}\end{LARGE} \\
% jeffwu@alum.mit.edu \hfill
Email {\tiny me@wuthejeff.com} \hfill
\href{http://wuthejeff.com}{Website {\tiny wuthejeff.com}}

% 858-405-1376  \hfill \href{https://github.com/WuTheFWasThat}{github.com/WuTheFWasThat}\\

\href{https://github.com/WuTheFWasThat}{Github {\tiny user WuTheFWasThat}}  \hfill \href{https://scholar.google.com/citations?user=x4JAvwMAAAAJ}{Google Scholar {\tiny user x4JAvwMAAAAJ}}\\
\end{center}

\noindent \textbf{Summary:}
Researcher and full-stack engineer
% Full-stack developer with research experience and wishing to do good.
interested in keeping the world safe for everyone as technologies such as machine learning become more powerful \\

%\begin{center}
%1466 Torrey Pines Road\\San Diego, CA 92037 \\
%\end{center}

%\hrule

%\begin{center}\begin{Large}\textsc{\textbf{Objective}\\}\end{Large}
%\end{center}

% \\

\hrule


\begin{center}\begin{Large}\textsc{\textbf{Work Experience}\\}\end{Large}\end{center}

\begin{itemize}
%   \item \textbf{OpenAI} Intern \hfill Oct 2016 \\
% Worked on internal dashboard

\item \textbf{OpenAI} Research engineer \hfill Aug 2018 -- Present \\
  AI safety research.  Worked on language modeling (including training \href{https://openai.com/blog/better-language-models/}{GPT-2}) and RLHF (trained initial \href{https://openai.com/blog/instruction-following/}{GPT instruct} series models).  Managed teams and projects working on scalable oversight, generalization, and interpretability.
% Managing small team within Alignment team
% TODO link blog post for instruct-series


\item \textbf{Google Research} Software engineer \hfill Oct 2016 -- Aug 2018 \\
Built general infrastructure
% (data pipelines, libraries, custom Tensorflow ops, a fun Lisp-like DSL)
for supporting models for personalization from cross-product user history (basically learning giant embedding spaces for all users, Chrome pages, Youtube videos, etc).
Experimented with RNN models to replace bag-of-words models, and contributed to launch of news feed trends personalization.
% In 20\% time, studied properties of generalization error.
% kriti says: Also Deep Trends turned out to be a success and all of us Sameer, me and Lianghao got promotions out of it.. so thanks for setting a great foundation!

\item \textbf{Terminal.com} Founding engineer \hfill Jan 2013 -- Oct 2016 \\
Building cloud-based container infrastructure, for scientific computing and online education.
Helped design and implement many core systems across the stack % e.g. main API, front-end, build/deployment, pricing, networking, snapshot genealogy
and oversaw their security and scalability.
Saw company grow from 2 to 12, and managed a small team of engineers.
Interfaced with clients, including Crunchbase, Stanford University, Codecademy, and Udacity.
Company was sold to Udacity.

\item \textbf{Probabilistic Computing Project} Master's student \hfill Nov 2011 -- Jan 2013 \\
Implemented a probabilistic programming language.
Explored a new Gibbs sampling algorithm to make inference more efficient in very general settings.
% Memory efficient Church inference with exchangeable foreign probabilistic procedures and JITing via reduced traces
Work presented \href{http://probabilistic-programming.org/wiki/NIPS*2012_Workshop/Schedule#poster-wu}{[at NIPS 2012 probabilistic programing workshop]}.
\href{https://github.com/WuTheFWasThat/PyChurch.}{[Source code]}
and
\href{https://github.com/WuTheFWasThat/PyChurch/blob/master/papers/MEng\%20thesis.pdf}{[thesis]}.


% \item \textbf{Google} Software Engineering Intern \hfill Jun 2012 -- Aug 2012 \\
% Improved landing page quality for Dynamic Search Ads.  Wrote MapReduces in C++ for identifying and finding replacements for pages with lower quality clicks.  %\hfill {Mountain View, CA}

% \item \textbf{6.006 Introduction to Algorithms} Teaching assistant \hfill Spring 2012, Fall 2012 \\
% \hfill {Cambridge, MA}

%   \item \textbf{Summer Program in Undergraduate Research} \hfill Jun 2011 -- Aug 2011\\
%  Proposed new technique based on linear algebra for making homomorphic encryption practical. %\hfill {Cambridge, MA}

%  \item \textbf{Language of Thought UROP} \hfill Jan 2011 -- May 2011\\
% Implemented linguistics tests on Mechanical Turk using Javascript.  Parsed and analyzed the data using R.% \hfill {Cambridge, MA}

% \item \textbf{Theory of Computation}  Grader \hfill Sep 2010 - Dec 2010\\
% \hfill {Cambridge, MA}

% \item \textbf{Applied Operations Research, Inc} Intern \hfill Jun 2010 -- Aug 2010\\
% % Navy contracted research; developed algorithms and models for random graph generation for solving ship routing problems
% Developed algorithms and models in MATLAB for ship routing under uncertain weather.  The simulations convinced the navy to adopt new weather prediction technologies.% \hfill {San Diego, CA}\\ \vspace{-15pt}

% \item \textbf{Probability and Random Variables} Grader \hfill Feb 2010 -- May 2010\\
% \hfill {Cambridge, MA}

%\item \textbf{National Economics Research Associates} Intern \hfill Jan 2010\\
%Analyzed financial data for economic consulting reports %\hfill {New York, NY}

% \item \textbf{Calculus with Theory} Teaching Assistant \hfill Sep 2009 -- May 2010\\
%Solving/typesetting problem sets, exams, solutions; website updating \hfill {Cambridge, MA}

% \item \textbf{Kumon Learning Center} \hfill  2006-2009 \\
% Tutored young children in math, and graded packets \hfill {San Diego, CA}

%\item \textbf{Qualcomm Information Technologies Intern} \hfill Jun 2008 -- Aug 2008\\
%Worked on application testing and optimization. %\hfill {San Diego, CA}

% \item \textbf{Burnham Institute for Medical Research Intern} \hfill Jun 2007 -- Aug 2007 \\
% Assistant in a lab for cancer/diabetes research.  \hfill {San Diego, CA}

%\item \textbf{Phenomix Pharmaceutical} \hfill  Jun 2007 \\
%Worked at my dad's company for a month.  Did inventory work and cared for laboratory animals. \hfill {San Diego, CA}

% \item \textbf{COSMOS Summer Program} \hfill  Jul 2006 -- Sep 2006\\
% Small research project and paper on pulsars and x-ray data\hfill {San Diego, CA}

%\item \textbf{NYU pathology lab}\hfill Jun 2006 \\
%Volunteered for two weeks.  Mixed buffers, helped carry out an autopsy.  \hfill {New York, NY}

\end{itemize}

\vspace{8pt}

\hrule

\begin{center}\begin{Large}\textsc{\textbf{Research}\\}\end{Large}\end{center}

I'm broadly interested in training AI systems that are honest and kind to humans, and assistive systems that make humans smarter or wiser.

\begin{itemize}

\item \textbf{Training large language models}
I scaled up OpenAI's largest language models 100x (from 110M parameters to 12B parameters).  % I also helped extensively with making efficient large-scale training infrastructure, implementing an evaluation suite, and building a web UI.
This included training \href{https://d4mucfpksywv.cloudfront.net/better-language-models/language_models_are_unsupervised_multitask_learners.pdf}{GPT-2} \href{https://openai.com/blog/better-language-models/}{[blog]} and early stepping stones towards \href{https://arxiv.org/pdf/2005.14165.pdf}{GPT-3} (NeurIPS 2020 best paper award),

\item \textbf{Reinforcement learning from human feedback}
I worked on helping language models learn from human feedback and specified human values. \href{https://openai.com/blog/learning-to-summarize-with-human-feedback/}{Early proofs of concept} trained models that produced summaries better than human-written ones.  This culminated in \href{https://openai.com/blog/instruction-following/}{instruction following models (InstructGPT)}, which were the predecessor to ChatGPT.

\item \textbf{Alignment in the superhuman regime}
I managed projects working on studying ML in the regime where humans cannot evaluate model outputs. \href{https://openai.com/index/critiques/}{Our work on scalable oversight} investigated whether models trained to self-critique could strengthen human supervision.  \href{https://openai.com/index/weak-to-strong-generalization/}{Our work on generalization} investigated whether models could behave as intended despite weak supervision.

\item \textbf{Interpretability at scale}
I managed projects working on understanding how large language models work.  We worked on \href{https://openai.com/index/extracting-concepts-from-gpt-4/}{disentangling building blocks at scale} and \href{https://openai.com/index/language-models-can-explain-neurons-in-language-models/}{automating their interpretations}.

% \item \textbf{Miscellaneous}
%   I also helped out on some miscellaneous projects, such as \href{https://cdn.openai.com/papers/Generative_Pretraining_from_Pixels_V2.pdf}{iGPT} (ICML 2020) and \href{https://arxiv.org/abs/2001.08361}{Scaling Laws for Neural Language Models}. \\

\end{itemize}
\hrule

\begin{center}\begin{Large}\textsc{\textbf{Side Projects}\\}\end{Large}\end{center}
%  \setlength\itemsep{0em}

I enjoy building software.  Here is a selection of projects I worked on mainly for fun.
For more, see \href{https://www.wuthejeff.com/projects}{my website}.


\begin{itemize}
\item \textbf{Vimflowy}
Note taking tool inspired by Vim and Workflowy. \href{https://www.wuthejeff.com/vimflowy}{[Demo]} \href{https://github.com/WuTheFWasThat/vimflowy}{[Source (Typescript)]}

\item \textbf{Hanabi simulation}
Game engine for simulating hanabi strategies, and state of the art bots.  Cited in \href{https://arxiv.org/abs/1902.00506}{DeepMind work} and \href{https://www.wsj.com/articles/why-the-card-game-hanabi-is-the-next-big-hurdle-for-artificial-intelligence-11553875351}{interviewed for in WSJ}. \href{https://github.com/WuTheFWasThat/hanabi.rs}{[Source (Rust)]}

% \item \textbf{EigenSeeClearlyNow}
% A linear-algebra visualization puzzle.  \href{https://github.com/WuTheFWasThat/EigenSeeClearlyNow}{[Source]} and \href{https://wuthejeff.com/spangame}{[Demo]}.

% \item \textbf{JSwidler challenge}
% Wrote solver for SAT variant, for challenge coworker wrote (\href{http://jswidler.com/challenge}{link}).

\item \textbf{Send A Damned Message}
  A simple puzzle game.
\href{https://www.wuthejeff.com/send-a-damned-message}{[Play here]}
\href{https://github.com/WuTheFWasThat/send-a-damned-message}{[Source (ReasonML)]}

% \item \textbf{cdict}
% A small library for hyperparameter management \href{https://github.com/WuTheFWasThat/cdict}{[source (Python)]}

% \item \textbf{tapystry}
% A small library for handling side effects in python, inspired by redux-saga \href{https://github.com/WuTheFWasThat/tapystry}{[source]}

% \item \textbf{plotserver}
% A small app for plotting results of ML jobs \href{https://github.com/WuTheFWasThat/plotserver}{[source]}

% \item \textbf{The Adventures of Flying Bear and Invisible Cat}
% A puzzle game written for my wife (then girlfriend). (\href{https://www.wuthejeff.com/bearcat-game}{Play here!})

\end{itemize}


\vspace{8pt}

\hrule

\begin{center}\begin{Large}\textsc{\textbf{Education}\\}\end{Large}
\end{center}

\noindent \textbf{Massachusetts Institute of Technology} \hfill \textbf{Cumulative GPA}: 4.8/5 \\
% \hfill Sep 2008 -- Jan 2013 \\
\begin{small}
\noindent {\bf B.S.} in Mathematics, {\bf B.S.} in Computer Science \hfill May 2012 \\
{\bf M.Eng.} in Computer Science \hfill January 2013 \\
\end{small}
% \hfill \textbf{GRE}: Verbal Reasoning: 164, Quantitative Reasoning: 170, Analytical Writing: 5.5\\
% 2011


% high school coursework
\begin{comment}
\begin{small}

 \noindent \textbf{Relevant Technical Coursework:}

\textbf{Physics}:
Physics III (Vibrations and Waves); Classical Mechanics II

 \textbf{Economics}:
 Microeconomics; % Principles of Microeconomics;
 Networks;
 Robust Mechanism Design;
Game Theory % Economic Applications of Game Theory
Public Finance and Public Policy

 \textbf{Math}:
 \noindent Real Analysis; % Analysis I;
 Linear Algebra and Group Theory; % Algebra I and II;
 Differential Forms; % Theory of Differential Forms;
 Combinatorial Analysis;
 Probability and Random Variables;
 Differential Equations;
 Seminar in Logic

\textbf{CS Theory}:
 Networks;
 Design and Analysis of Algorithms; % Algorithms; %
 Approximation Algorithms;
 Sub-Linear Algorithms;
 Complexity Theory I and II; % Theory of Computation;
 Advanced Complexity Theory;
 Quantum Complexity Theory;
 Combinatorial Optimization;
 Cryptography I and II; % Cryptography and Cryptanalysis
 Modern Developments in Cryptography
 Artificial Intelligence;

 \textbf{CS Systems}:
Intro to EECS I and II;
 Computer Systems Engineering;
 Elements of Software Construction;
 Computation Structures;
 Performance Engineering of Software Systems
 \end{small} \\
\end{comment}

% high school
\begin{comment}

\begin{center}\textbf{The Bishop's School, La Jolla, CA} \end{center} \vspace{-6 pt}

\textbf{Date of graduation}: May 2008, cum laude \hfill \textbf{GPA}: 4.66/5

\begin{small}

$\bullet$ National AP Scholar, 3$\times$ USAMO qualifier \hfill \textbf{ACT}: 34, \textbf{SAT}: 2230\\

% SAT = 800 math, 700 critical reading, 730 writing
% ACT = 34 (english, math 36, reading, science 32, writing)

% $\bullet$ National AP Scholar (5's in Statistics, Calculus BC, Chinese, Chemistry, Microeconomics, Macroeconomics, Physics C Mechanics, Physics C E\&M)

% $\bullet$ Independent studies in C++ and physics.  College level differential equations and linear algebra \\

%$\bullet$ Did over 100 hours of community service, including helping out at an 8 hour Halloween fair for kids\\

\end{small}

\end{comment}
\hrule

\vspace{8 pt}
\begin{center}\begin{Large}\textsc{\textbf{Skills}\\}\end{Large}\end{center}

% Front end: Javascript, Typescript, React, Redux, Saga, HTML/CSS
% $\bullet$ Proficient: Javascript/Typescript, C++, Python.  Familiar: Rust, bash, Go, Java, HTML/CSS. % (lua, haskell, ruby, C++, C, matlab, \LaTeX)

$\bullet$ Deep learning and machine learning (especially language modeling, RL, reward learning)

% $\bullet$ Machine learning frameworks (Tensorflow, pytorch)

$\bullet$ Front end development %, e.g. React frameworks
% Git, Vim, HTML/CSS, MongoDB, databases?, Nginx,
% , MapReduce and analysis

$\bullet$ Devops, e.g. linux, cloud platforms, containers, databases % Kubernetes % \hfill % AWS/GCP/Azure,

$\bullet$ Algorithms and distributed systems design

$\bullet$ CS theory (e.g. complexity theory, cryptography) % \hfill

$\bullet$ Mathematics (2006-2008 USAMO, 2010 Putnam top 200)

% $\bullet$ Productivity \hfill
% $\bullet$ Learning new skills

%$\bullet$ English (native), Mandarin (fluent speaking/listening)

\vspace{8 pt}

\hrule

\begin{center}\begin{Large}\textsc{\textbf{Personal qualities}\\}\end{Large}\end{center}

$\bullet$ I enjoy working with people who share my mission, and who bring some thinking that I don't

$\bullet$ I like to keep an eye on the big picture, and I tend to think abstractly/idealistically

$\bullet$ I strive to act with integrity

$\bullet$ I try to be open-minded

% $\bullet$ Cares about other people.


% IN PRESS:
% GPT-2
% crappy quote: https://www.newscientist.com/article/2205876-fake-news-generating-ais-could-be-the-best-weapons-to-fight-fake-news/
% also pretty meh quote: https://www.theverge.com/2019/2/14/18224704/ai-machine-learning-language-models-read-write-openai-gpt2
% misquote?: https://medium.com/syncedreview/openai-guards-its-ml-model-code-data-to-thwart-malicious-usage-d9f7e9c43cd0
% https://www.vox.com/2019/5/15/18623134/openai-language-ai-gpt2-poetry-try-it
% https://www.newyorker.com/magazine/2019/10/14/can-a-machine-learn-to-write-for-the-new-yorker
% has my picture, negative-ish article though: https://www.technologyreview.com/2020/02/17/844721/ai-openai-moonshot-elon-musk-sam-altman-greg-brockman-messy-secretive-reality/

% RECORDED TALKS
% SPC https://www.youtube.com/watch?v=t6o49g0alPs
% EA Cambridge https://www.youtube.com/watch?v=cqu_i611kbw

\begin{comment}

\vspace{12 pt}
\hrule

\begin{center}\begin{Large}\textsc{\textbf{Awards and Honors}\\}\end{Large}\end{center}

\begin{small}
\noindent
% \textbf{Interview Street CodeSprint, 15th place} \hfill 2011\\  % ???
\textbf{William Lowell Putnam Mathematical Competition Top 200} \hfill 2010\\
% \textbf{William Lowell Putnam Mathematical Competition Top 500} \hfill 2008, 2009\\
% 6.172 projects top??
%\textbf{6.005 (Elements of Software Construction) final project Best UI award} \hfill 2010\\%(collaborative text editor)
%  \textbf{Novartis National Merit Corporate Scholarship} %\$1000 / year  (2008-2012);
% \textbf{UCSD Annual High School Honors Math Contest} 2$^{nd}$ (2007), 1$^{st}$ place (2008);
%\textbf{Caltech Signature Award} (2007);
%\textbf{Bausch and Lomb Honorary Science Award} (2007);
\textbf{USA Mathematics Olympiad qualifier} \hfill 2006, 2007, 2008
%\textbf{Bishop's Math Department Award} (2006, 2007, 2008);
%  \textbf{Kumon Math Challenge} 1$^{st}$ place in North America, \$1500 (2005)
%  reviewer for ICLR, Neurips

\end{small}
\vspace{8 pt}
\end{comment}

\begin{comment}

\hrule

%\begin{center}\begin{Large}\textsc{\textbf{Leadership}\\}\end{Large}\end{center}

%  Founding member of THINK at MIT

%\begin{itemize}

%\item

%\end{itemize}


\hrule

\begin{center}\begin{Large}\textsc{\textbf{Activities}\\}\end{Large}\end{center}
\begin{itemize}
% SPARC
\item Reviewer for NEURIPS, ICLR
\item 2009, 2010, 2011 - Wrote/reviewed problems, graded, and helped make decisions for the HMMT contests
%\item test solve usaco?  project euler?
%\item SPARC
\item 2011 - Taught an 8-week class for high school students about computability and complexity theory, through the HSSP program
%\item  piano, intramural sports

% THINK

\end{itemize}
\end{comment}

\end{document}
